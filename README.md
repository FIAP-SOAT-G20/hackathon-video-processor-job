# <p align="center"><b>Video Processor Job</b> <small>FIAP Hackathon - Video Frame Extraction Service</small></p>

<p align="center">
    <img src="https://img.shields.io/badge/Code-Go-informational?style=flat-square&logo=go&color=00ADD8" alt="Go" />
    <img src="https://img.shields.io/badge/Cloud-AWS_Lambda-informational?style=flat-square&logo=awslambda&color=FF9900" alt="AWS Lambda" />
    <img src="https://img.shields.io/badge/Storage-S3-informational?style=flat-square&logo=amazons3&color=569A31" alt="S3" />
    <img src="https://img.shields.io/badge/Tools-FFmpeg-informational?style=flat-square&logo=ffmpeg&color=007808" alt="FFmpeg" />
    <img src="https://img.shields.io/badge/Tools-Docker-informational?style=flat-square&logo=docker&color=2496ED" alt="Docker" />
    <img src="https://img.shields.io/badge/Tools-Make-informational?style=flat-square&logo=make&color=6D00CC" alt="Make" />
</p>

## ğŸ’¬ About

AWS Lambda function developed for the FIAP Hackathon that processes video files and extracts frames using FFmpeg. The service follows Clean Architecture principles and handles video processing in a serverless environment.

### Key Features

- **Video Processing**: Extracts frames from uploaded video files at configurable frame rates
- **Frame Extraction**: Uses FFmpeg to extract frames as PNG or JPG images (configurable)
- **ZIP Compression**: Packages extracted frames into a downloadable ZIP file (uploaded to S3)
- **S3 Integration**: Downloads videos from S3, uploads processed frames, and cleans up original files
- **Serverless**: Runs as AWS Lambda function with optimized performance
- **Clean Architecture**: Well-structured codebase following Clean Architecture principles

## ğŸ—ï¸ Architecture

This service implements Clean Architecture with the following layers:

```
â”œâ”€â”€ main.go                     # Entry point and dependency injection
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ core/                   # Business logic layer
â”‚   â”‚   â”œâ”€â”€ domain/entity/      # Business entities
â”‚   â”‚   â”œâ”€â”€ dto/                # Data transfer objects
â”‚   â”‚   â”œâ”€â”€ port/               # Interface contracts
â”‚   â”‚   â””â”€â”€ usecase/            # Business use cases
â”‚   â”œâ”€â”€ adapter/                # Interface adapters
â”‚   â”‚   â”œâ”€â”€ controller/         # Request handlers
â”‚   â”‚   â”œâ”€â”€ gateway/            # External service interfaces
â”‚   â”‚   â””â”€â”€ presenter/          # Response formatting
â”‚   â””â”€â”€ infrastructure/         # External concerns
â”‚       â”œâ”€â”€ datasource/         # Data access implementations
â”‚       â”œâ”€â”€ service/            # External service implementations
â”‚       â”œâ”€â”€ aws/lambda/         # Lambda-specific handlers
â”‚       â””â”€â”€ logger/             # Logging utilities
```

## ğŸ”„ Processing Flow

1. **Input**: Lambda receives event with video S3 key
2. **Download**: Video file downloaded from S3 to Lambda's `/tmp` directory
3. **Validation**: Video format validation using FFprobe
4. **Processing**: Frame extraction using FFmpeg at specified frame rate (default: 1 fps)
5. **Compression**: Extracted frames packaged into ZIP file
6. **Upload**: ZIP file uploaded to processed images S3 bucket
7. **Cleanup**: Original video deleted from source bucket and temporary files cleaned up
8. **Response**: Returns processing result with output location and frame count

## ğŸš€ Getting Started

### Prerequisites

- Go 1.25+
- FFmpeg (for local development)
- AWS CLI configured
- Docker (for containerized builds)

### Environment Variables

```bash
VIDEO_BUCKET=your-raw-video-bucket          # S3 bucket for input videos
PROCESSED_BUCKET=your-processed-images-bucket # S3 bucket for output ZIP files
```

### Local Development

```bash
# Install dependencies
make deps

# Run tests
make test

# Build binary
make build

# Run locally (requires video file)
make run
```

### Lambda Deployment

```bash
# Build Lambda deployment package
make build-lambda

# Deploy to AWS (requires terraform or SAM)
make deploy
```

## ğŸ“‹ Usage

### Lambda Event Format

```json
{
  "video_key": "path/to/video.mp4",
  "configuration": {
    "frame_rate": 1.0,
    "output_format": "png"
  }
}
```

### Response Format

Note: output_key is the S3 object key for the generated ZIP in the processed bucket. Construct a public URL as needed (e.g., via a CDN or S3 access policy).

```json
{
  "success": true,
  "message": "Video processed successfully. 120 frames extracted.",
  "output_key": "processed/path/to/video_frames.zip",
  "frame_count": 120
}
```

## ğŸ› ï¸ Development

### Project Structure

- **Domain Layer**: Pure business logic without external dependencies
- **Application Layer**: Use cases orchestrating business workflows  
- **Interface Layer**: Controllers, presenters, and gateways
- **Infrastructure Layer**: External services, databases, and frameworks

### Key Components

- **VideoProcessor**: FFmpeg integration for frame extraction
- **FileManager**: Temporary file management in Lambda environment
- **StorageDataSource**: S3 operations for video and frame storage
- **VideoController**: Lambda event handling and response formatting

## ğŸ§ª Testing

### Unit tests (with testify)

- Run unit tests: `make unit-test`
- Check coverage (fails if < 80%): `make coverage-check`

### BDD tests (Godog + testify)

- Define scenarios in `tests/features/*.feature`
- Run BDD tests: `make bdd-test`

### Mocks (Uber mockgen)

- Generate mocks for ports: `make mock`
- The generator uses `go.uber.org/mock/mockgen`. Generated files are stored under `internal/core/port/mocks`.

```bash
# Run unit tests
make test

# Run tests with coverage
make test-coverage

# Run integration tests (requires AWS credentials)
make test-integration
```

## ğŸ“¦ Deployment

### CI/CD (GitHub Actions)

This repo includes workflows to enforce quality and ship images:

- `ci-unit-test.yml`: runs unit tests and enforces >= 80% coverage
- `ci-bdd-tests.yml`: runs BDD tests with Godog
- `ci-build-deploy.yml`: builds and pushes the Docker image to ECR after BDD passes on `main`

Required repository secrets:

- `AWS_ACCESS_KEY_ID`, `AWS_SECRET_ACCESS_KEY`, `AWS_SESSION_TOKEN` (if applicable)
- `AWS_REGION` (e.g., `us-east-1`)
- `ECR_REPOSITORY` (e.g., `fiap-hackathon-dev-video-processor`)

Images are tagged as `latest` and `${{ github.sha }}`.

### Docker Container

```bash
# Build container image
make docker-build

# Push to ECR
make docker-push
```

### AWS Lambda

The service is designed to run as AWS Lambda function with:

- **Runtime**: Custom container or Go 1.x runtime
- **Memory**: 1024MB+ (for video processing)
- **Timeout**: 5-15 minutes (depending on video size)
- **Storage**: 512MB+ `/tmp` space for temporary files

## ğŸ”§ Configuration

### Processing Configuration

- **frame_rate**: Frames per second to extract (default: 1.0)
- **output_format**: Output image format (default: "png", supports: png, jpg)

### S3 Bucket Structure

```
raw-videos/
â”œâ”€â”€ video1.mp4
â”œâ”€â”€ video2.avi
â””â”€â”€ ...

processed-images/  
â”œâ”€â”€ processed/video1_frames.zip
â”œâ”€â”€ processed/video2_frames.zip
â””â”€â”€ ...
```

## ğŸ“ˆ Performance

- **Cold Start**: ~2-3 seconds
- **Processing**: ~30-60 seconds per minute of video
- **Memory Usage**: Scales with video resolution and length
- **Concurrent Executions**: Configurable based on workload

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team

FIAP SOAT G20 - Hackathon Team

---

<p align="center">Made with â¤ï¸ for FIAP Hackathon</p>